from pyspark.sql import SparkSession
from pyspark.ml.feature import VectorAssembler
from pyspark.ml.classification import LogisticRegression
from pyspark.ml.evaluation import BinaryClassificationEvaluator

# Initialize Spark session
spark = SparkSession.builder.appName("MLlibExample").getOrCreate()

# Load dataset
data = spark.read.csv("hdfs:///data/large_dataset.csv", header=True, inferSchema=True)

# Feature engineering
assembler = VectorAssembler(inputCols=['feature1', 'feature2', 'feature3'], outputCol='features')
data_prepared = assembler.transform(data).select('features', 'label')

# Split data
train, test = data_prepared.randomSplit([0.8, 0.2])

# Initialize and train the model
lr = LogisticRegression(featuresCol='features', labelCol='label')
model = lr.fit(train)

# Make predictions
predictions = model.transform(test)

# Evaluate the model
evaluator = BinaryClassificationEvaluator(labelCol='label')
auc = evaluator.evaluate(predictions, {evaluator.metricName: "areaUnderROC"})

print(f"AUC: {auc}")

# Stop Spark session
spark.stop()
