from pyspark.sql import SparkSession
import matplotlib.pyplot as plt

# Initialize Spark Session
spark = SparkSession.builder \
    .appName("BigDataAnalysisExample") \
    .getOrCreate()

# Generate a large dataset
data = [("Category " + str(i % 10), i) for i in range(1, 1000001)]  # 1 million records
df = spark.createDataFrame(data, ["Category", "Value"])

# Perform analysis: Calculate count per category
category_counts = df.groupBy("Category") \
    .count() \
    .orderBy("Category") \
    .collect()

# Prepare data for plotting
categories = [row['Category'] for row in category_counts]
counts = [row['count'] for row in category_counts]

# Plot the results
plt.figure(figsize=(10, 6))
plt.bar(categories, counts, color='skyblue')
plt.xlabel('Category')
plt.ylabel('Count')
plt.title('Counts per Category')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# Stop the Spark session
spark.stop()





